{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 16, 'font.family': 'sans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_yelp_2(query):\n",
    "    \"\"\"\n",
    "    Connects to yelp_2 database on Postgres and\n",
    "    loads a Pandas dataframe based off sql query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Sql query to select data from yelp_2.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Pandas dataframe of records\n",
    "                    from sql query of yelp_2 database.\n",
    "    \"\"\"\n",
    "    connect = 'postgresql+psycopg2://postgres:password@localhost:5432/yelp_2'\n",
    "    engine = create_engine(connect)\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "    df = df.copy()\n",
    "    return df\n",
    "\n",
    "def counter(x):\n",
    "    if x in ['None', None, '']:\n",
    "        return 0\n",
    "    else:\n",
    "        y = x.split(',')\n",
    "        return len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT *\n",
    "        FROM all_features\n",
    "        LIMIT 10000\n",
    "        ;\n",
    "        '''\n",
    "df = load_dataframe_from_yelp_2(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_release_date = pd.to_datetime('2020-3-25 19:13:01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_date'] = pd.to_datetime(df['review_date'], unit='ms')\n",
    "df['user_yelping_since'] = pd.to_datetime(df['user_yelping_since'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targets\n",
    "Combination of review useful, funny, and cool vote counts evenly weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No discounting or scaling\n",
    "df['T1_REG_ufc_total'] = df[['review_useful', 'review_funny', 'review_cool']].sum(axis=1)\n",
    "df['T2_CLS_ufc_votes_or_not'] = df['T1_REG_ufc_total'] > 0\n",
    "def usefulness_level(x):\n",
    "    if x == 0:\n",
    "        return 'zero'\n",
    "    elif x < 10:\n",
    "        return 'low'\n",
    "    elif x < 100:\n",
    "        return 'medium'\n",
    "    elif x >= 100:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "df['T3_CLS_ufc_level'] = df['T1_REG_ufc_total'].apply(usefulness_level)\n",
    "# Time discounted\n",
    "def target_time_discount(ufc_total, review_date):\n",
    "    return (ufc_total / ((dataset_release_date - review_date).days)) * 365\n",
    "\n",
    "df['T4_REG_ufc_per_year'] = df.apply(lambda x: target_time_discount(x.T1_REG_ufc_total, x.review_date), axis=1)\n",
    "df['T5_CLS_ufc_per_year_level'] = df['T4_REG_ufc_per_year'].apply(usefulness_level)\n",
    "# Time and Business Popularity Discounted\n",
    "df['T6_REG_ufc_per_year_bus_disc'] = df['T4_REG_ufc_per_year'] / df['business_review_count']\n",
    "\n",
    "df.drop(labels=['review_useful', 'review_funny', 'review_cool'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nan/Null Values\n",
    "Extremely small percentage were Nan/Null\n",
    "    so dropping all rows with the Nan/Nulls.\n",
    "Other Nan/Nulls avoided during sql joins and eda_prep.\n",
    "Due to the large amount of records available\n",
    "    and the relative completeness of the data,\n",
    "    I am being liberal with dropping incomplete records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Columns\n",
    "Columns that represent similar data\n",
    "    that don't have individual value\n",
    "    are summed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compliment_columns = ['user_compliment_hot', 'user_compliment_more', \n",
    "                      'user_compliment_profile', 'user_compliment_cute',\n",
    "                      'user_compliment_list', 'user_compliment_note',\n",
    "                      'user_compliment_plain', 'user_compliment_cool',\n",
    "                      'user_compliment_funny', 'user_compliment_writer',\n",
    "                      'user_compliment_photos']\n",
    "df['user_compliments'] = df[compliment_columns].sum(axis=1)\n",
    "df.drop(labels=compliment_columns, axis=1, inplace=True)\n",
    "\n",
    "df['user_total_ufc'] = df[['user_useful', 'user_funny', 'user_cool']].sum(axis=1)\n",
    "df.drop(labels=['user_useful', 'user_funny', 'user_cool'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elite(x):\n",
    "    elite_count = 0 \n",
    "    if x in ['None', None, '']:\n",
    "        elite_count = 0\n",
    "    else:\n",
    "        y = x.split(',')\n",
    "        elite_count = len(y)\n",
    "    return elite_count\n",
    "\n",
    "df['user_elite_count'] = df.user_elite.apply(count_elite)\n",
    "\n",
    "def years_since_most_recent_elite(x):\n",
    "    z = 0 \n",
    "    if x in ['None', None, '']:\n",
    "        z = 0\n",
    "    else:    \n",
    "        y = pd.to_numeric(x.split(','))\n",
    "        z = max(y)\n",
    "    return 2020 - z\n",
    "\n",
    "df['user_elite_most_recent'] = df.user_elite.apply(years_since_most_recent_elite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elite_td(user_elite, review_date):\n",
    "    if user_elite in ['None', None, '']:\n",
    "        return 0\n",
    "    else:\n",
    "        split_elites = user_elite.split(',')\n",
    "        elites_pre_review = [elite for elite in split_elites if pd.to_datetime(elite) < review_date]\n",
    "        return len(elites_pre_review)\n",
    "\n",
    "df['user_elite_count_td'] = df.apply(lambda x: count_elite_td(x.user_elite, x.review_date), axis=1)\n",
    "\n",
    "def years_since_most_recent_elite_td(user_elite, review_date): \n",
    "    z = 0\n",
    "    if user_elite in ['None', None, '']:\n",
    "        z = 0\n",
    "    else:    \n",
    "        split_elites = pd.to_numeric(user_elite.split(','))\n",
    "        elites_pre_review = [elite for elite in split_elites if pd.to_datetime(elite) < review_date]\n",
    "        if len(elites_pre_review) == 0:\n",
    "            z = 0\n",
    "        else:\n",
    "            z = max(elites_pre_review)\n",
    "    return review_date.year - z\n",
    "df['user_elite_most_recent_td'] = df.apply(lambda x: years_since_most_recent_elite_td(x.user_elite, x.review_date), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Other User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_needing_time_discounting = ['user_total_ufc', 'user_compliments', 'user_review_count', 'user_fans', 'user_friend_count']\n",
    "\n",
    "def user_time_discount(count_feature, user_yelping_since, review_date):\n",
    "    return (count_feature / (dataset_release_date - user_yelping_since).days) * ((review_date - user_yelping_since).days)\n",
    "\n",
    "for feature in user_features_needing_time_discounting:\n",
    "    df[f'{feature}_td'] = df.apply(lambda x: user_time_discount(x[feature], x.user_yelping_since, x.review_date), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Checkin and Review Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_features_needing_time_discounting = ['business_review_count', 'business_checkin_count']\n",
    "\n",
    "def business_time_discount(count_feature, oldest_checkin, review_date):\n",
    "    return (count_feature / (dataset_release_date - oldest_checkin).days) * ((review_date - oldest_checkin).days)\n",
    "\n",
    "for feature in business_features_needing_time_discounting:\n",
    "    df[f'{feature}_td'] = df.apply(lambda x: business_time_discount(x[feature], x.business_oldest_checkin, x.review_date), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'user_id', 'business_id', 'review_stars', 'review_date', 'business_latitude',\n",
       "       'business_longitude', 'business_avg_stars', 'business_review_count', 'business_is_open',\n",
       "       'business_categories', 'business_checkin_count', 'business_oldest_checkin',\n",
       "       'business_newest_checkin', 'user_avg_stars', 'user_review_count', 'user_yelping_since',\n",
       "       'user_fans', 'user_friend_count', 'user_elite', 'T1_REG_ufc_total',\n",
       "       'T2_CLS_ufc_votes_or_not', 'T3_CLS_ufc_level', 'T4_REG_ufc_per_year',\n",
       "       'T5_CLS_ufc_per_year_level', 'T6_REG_ufc_per_year_bus_disc', 'user_compliments',\n",
       "       'user_total_ufc', 'user_elite_count', 'user_elite_most_recent', 'user_elite_count_td',\n",
       "       'user_elite_most_recent_td', 'user_total_ufc_td', 'user_compliments_td',\n",
       "       'user_review_count_td', 'user_fans_td', 'user_friend_count_td', 'business_review_count_td',\n",
       "       'business_checkin_count_td'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
