{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welcome-accused",
   "metadata": {},
   "source": [
    "# Text Processing - Yelp 2021 - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-broad",
   "metadata": {},
   "source": [
    "This notebook covers:\n",
    "* Linguistic Characterics (parts-of-speech, named entities, syntactic relationships - Spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-flower",
   "metadata": {},
   "source": [
    "## Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Main NLP library\n",
    "import spacy\n",
    "# Connecting to Postgres RDS on AWS\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects import postgresql\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-cursor",
   "metadata": {},
   "source": [
    "## Import Data in Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_endpoint = None\n",
    "db_name = \"yelp_2021_db\"\n",
    "db_password = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{db_password}@{db_endpoint}/{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-front",
   "metadata": {},
   "source": [
    "## Linguistic Components with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\",\n",
    "            \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\",]\n",
    "dep_list = [\"ROOT\", \"acl\", \"acomp\", \"advcl\", \"advmod\", \"agent\", \"amod\",\n",
    "            \"appos\", \"attr\", \"aux\", \"auxpass\", \"case\", \"cc\", \"ccomp\",\n",
    "            \"compound\", \"conj\", \"csubj\", \"csubjpass\", \"dative\", \"dep\", \"det\",\n",
    "            \"dobj\", \"expl\", \"intj\", \"mark\", \"meta\", \"neg\", \"nmod\", \"npadvmod\",\n",
    "            \"nsubj\", \"nsubjpass\", \"nummod\", \"oprd\", \"parataxis\", \"pcomp\",\n",
    "            \"pobj\", \"poss\", \"preconj\", \"predet\", \"prep\", \"prt\", \"punct\",\n",
    "            \"quantmod\", \"relcl\",\"xcomp\"]\n",
    "ent_list = [\"CARDINAL\", \"DATE\", \"EVENT\", \"FAC\", \"GPE\", \"LANGUAGE\", \"LAW\",\n",
    "            \"LOC\", \"MONEY\", \"NORP\", \"ORDINAL\", \"ORG\", \"PERCENT\", \"PERSON\",\n",
    "            \"PRODUCT\", \"QUANTITY\", \"TIME\", \"WORK_OF_ART\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spacy_features(df, text_feature_name):\n",
    "    \"\"\"\n",
    "    Adds various features using Spacy's library and NLP models.\n",
    "\n",
    "    Key Terms:\n",
    "        pos_dict: Part of Speech\n",
    "                  https://universaldependencies.org/u/pos/\n",
    "\n",
    "        dep_list: Universal Dependency Relations\n",
    "                  https://universaldependencies.org/u/dep/\n",
    "\n",
    "        ent_list: Named Entity\n",
    "                  https://spacy.io/api/annotation#named-entities\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"spacy_doc\"] = df[text_feature_name].apply(lambda x: nlp(x))\n",
    "    df.drop(\"review_text\", axis=1, inplace=True)\n",
    "    \n",
    "    df[\"token_count\"] = df[\"spacy_doc\"].apply(lambda x: len(x))\n",
    "    df[\"stopword_perc\"] = df[\"spacy_doc\"].apply(lambda x: round(len([token for token in x if token.is_stop]) / len(x), 5))\n",
    "    df[\"stopword_count\"] = df[\"spacy_doc\"].apply(lambda x: len([token for token in x if token.is_stop]))\n",
    "    df[\"ent_perc\"] = df[\"spacy_doc\"].apply(lambda x: round(len(x.ents) / len(x), 5))\n",
    "    df[\"ent_count\"] = df[\"spacy_doc\"].apply(lambda x: len(x.ents))\n",
    "    \n",
    "    for pos in pos_list:\n",
    "        df[f\"pos_{pos.lower()}_perc\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: round(len([token for token in x if token.pos_ == pos]) / len(x), 5))\n",
    "        df[f\"pos_{pos.lower()}_count\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: len([token for token in x if token.pos_ == pos]))\n",
    "\n",
    "    for dep in dep_list:\n",
    "        df[f\"dep_{dep.lower()}_perc\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: round(len([token for token in x if token.dep_ == dep]) / len(x), 5))\n",
    "        df[f\"dep_{dep.lower()}_count\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: len([token for token in x if token.dep_ == dep]))\n",
    "    \n",
    "    for ent in ent_list:\n",
    "        df[f\"ent_{ent.lower()}_perc\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: round(len([y for y in x.ents if y.label_ == ent]) / len(x), 5))\n",
    "        df[f\"ent_{ent.lower()}_count\"] = df[\"spacy_doc\"].apply(\n",
    "            lambda x: len([y for y in x.ents if y.label_ == ent]))\n",
    "\n",
    "    df.drop(\"spacy_doc\", axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-laundry",
   "metadata": {},
   "source": [
    "## Run Spacy Function and Save to AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records_processed = 0\n",
    "# for chunk in pd.read_sql(sql='SELECT review_id, review_text FROM text_data_train_b',\n",
    "#                          con=engine, chunksize=chunksize):\n",
    "#     text = create_spacy_features(chunk, 'review_text')\n",
    "#     records_processed += text.shape[0]\n",
    "#     print(f'Total records processed: {records_processed}')\n",
    "#     text.to_sql('text_data_train_spacy_bs', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records_processed = 0\n",
    "# for chunk in pd.read_sql(sql='SELECT review_id, review_text FROM text_data_test_b',\n",
    "#                          con=engine, chunksize=chunksize):\n",
    "#     text = create_spacy_features(chunk, 'review_text')\n",
    "#     records_processed += text.shape[0]\n",
    "#     print(f'Total records processed: {records_processed}')\n",
    "#     text.to_sql('text_data_test_bs', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-tuesday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
