{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welcome-accused",
   "metadata": {},
   "source": [
    "# Text Processing - Yelp 2021 - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-matthew",
   "metadata": {},
   "source": [
    "This notebook covers:\n",
    "* Word Embedding Models\n",
    "* Word2Vec\n",
    "* Doc2Vec\n",
    "* Bert\n",
    "* Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-flower",
   "metadata": {},
   "source": [
    "## Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reverse-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "# Main NLP libraries\n",
    "import nltk\n",
    "import gensim\n",
    "# Word2Vec\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# Fasttext\n",
    "import csv\n",
    "import fasttext\n",
    "from gensim.utils import simple_preprocess\n",
    "# Bert - DistilBert\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-cursor",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_endpoint = None\n",
    "db_name = \"yelp_2021_db\"\n",
    "db_password = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://postgres:{db_password}@{db_endpoint}/{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stylish-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query = \"SELECT review_id, review_text, target_ufc_bool FROM text_data_train LIMIT 10000\"\n",
    "test_query = \"SELECT review_id, review_text, target_ufc_bool FROM text_data_test LIMIT 1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_sql(sql=train_query, con=engine)\n",
    "test = pd.read_sql(sql=test_query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-teaching",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "responsible-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>target_ufc_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b38E-oxRIxaSYmuujX_JyQ</td>\n",
       "      <td>Yes. Jim-Jim's is your weekend getaway from ev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b3Bpwf-uAvyGzSDRBPdqJA</td>\n",
       "      <td>This is the best Brazilian place I've been. th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3KT6N_5yLXEKtHqTohHYA</td>\n",
       "      <td>Great concept...I just recently discovered pok...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b3Pn006eyKgEkajiVDCztQ</td>\n",
       "      <td>Avoid this hotel like the plague. Unreasonable...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b3nDpB331MD8_iylpZK_dQ</td>\n",
       "      <td>We went to dinner here yesterday and to say we...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                                        review_text  \\\n",
       "0  b38E-oxRIxaSYmuujX_JyQ  Yes. Jim-Jim's is your weekend getaway from ev...   \n",
       "1  b3Bpwf-uAvyGzSDRBPdqJA  This is the best Brazilian place I've been. th...   \n",
       "2  b3KT6N_5yLXEKtHqTohHYA  Great concept...I just recently discovered pok...   \n",
       "3  b3Pn006eyKgEkajiVDCztQ  Avoid this hotel like the plague. Unreasonable...   \n",
       "4  b3nDpB331MD8_iylpZK_dQ  We went to dinner here yesterday and to say we...   \n",
       "\n",
       "  target_ufc_bool  \n",
       "0            True  \n",
       "1           False  \n",
       "2            True  \n",
       "3            True  \n",
       "4            True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "systematic-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   review_id         1000 non-null   object\n",
      " 1   review_stars      1000 non-null   int64 \n",
      " 2   review_text       1000 non-null   object\n",
      " 3   target_ufc_bool   1000 non-null   object\n",
      " 4   target_ufc_count  1000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ambient-fortune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     522\n",
       "False    478\n",
       "Name: target_ufc_bool, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Counts')\n",
    "train.target_ufc_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complex-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     528\n",
       "False    472\n",
       "Name: target_ufc_bool, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Counts')\n",
    "test.target_ufc_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sufficient-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Percent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    0.52200\n",
       "False   0.47800\n",
       "Name: target_ufc_bool, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Percent')\n",
    "train.target_ufc_bool.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finite-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Percent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    0.52800\n",
       "False   0.47200\n",
       "Name: target_ufc_bool, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Percent')\n",
    "test.target_ufc_bool.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-texas",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-sleeve",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/jungealexander/word2vec-and-random-forest-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-exhaust",
   "metadata": {},
   "source": [
    "### Preprocessing for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "genuine-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer used for splitting reviews into sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elegant-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Convert a review to a list of words. Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indonesian-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Split review into list of sentences where each sentence is a list of words.\n",
    "    Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "    # each sentence is furthermore split into words\n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "framed-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = []\n",
    "for review in train['review_text']:\n",
    "    training_text += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "passing-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'visited',\n",
       " 'kyma',\n",
       " 'last',\n",
       " 'week',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'and',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'it']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-charger",
   "metadata": {},
   "source": [
    "### Training Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chicken-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various word2vec parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 1    # Minimum word count                        \n",
    "num_workers = 3       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "\n",
    "w2v_model = Word2Vec(sentences=training_text,\n",
    "                     workers=num_workers, vector_size=num_features,\n",
    "                     min_count=min_word_count, window=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-experience",
   "metadata": {},
   "source": [
    "### Pre-Trained Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sitting-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goog_w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-laundry",
   "metadata": {},
   "source": [
    "### Preprocessing for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spatial-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features, local_trained_model):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0\n",
    "    if local_trained_model:\n",
    "        index2word_set = set(model.wv.index_to_key)  # words known to the model\n",
    "        for word in words:\n",
    "            if word in index2word_set: \n",
    "                nwords += 1\n",
    "                feature_vec = np.add(feature_vec,model.wv.get_vector(word))\n",
    "    else:\n",
    "        index2word_set = set(model.index_to_key)\n",
    "        for word in words:\n",
    "            if word in index2word_set: \n",
    "                nwords += 1\n",
    "                feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "great-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_feature_vecs(reviews, model, num_features, local_trained_model):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for all reviews\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for review in reviews:\n",
    "        review_feature_vecs[counter] = make_feature_vec(review, model, num_features, local_trained_model)\n",
    "        counter += 1\n",
    "    return review_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "portuguese-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average feature vectors for training and test sets\n",
    "clean_train_reviews = []\n",
    "for review in train['review_text']:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = get_avg_feature_vecs(clean_train_reviews, w2v_model, num_features, True)\n",
    "\n",
    "clean_test_reviews = []\n",
    "for review in test['review_text']:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "testDataVecs = get_avg_feature_vecs(clean_test_reviews, w2v_model, num_features, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-boundary",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wooden-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "forest = forest.fit(trainDataVecs, train['target_ufc_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-independence",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "numeric-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cls_results = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-filing",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "welcome-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.54      0.54       472\n",
      "        True       0.59      0.58      0.58       528\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.56      0.56      0.56      1000\n",
      "weighted avg       0.56      0.56      0.56      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['target_ufc_bool'], w2v_cls_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-shannon",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-minister",
   "metadata": {},
   "source": [
    "https://fasttext.cc/docs/en/supervised-tutorial.html  \n",
    "https://towardsdatascience.com/fasttext-for-text-classification-a4b38cbff27c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-creator",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "jewish-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review_text'] = train['review_text'].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "train['target_ufc_bool'] = train['target_ufc_bool'].apply(lambda x: '__label__' + x)\n",
    "\n",
    "test['review_text'] = test['review_text'].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "test['target_ufc_bool'] = test['target_ufc_bool'].apply(lambda x: '__label__' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verbal-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['target_ufc_bool', 'review_text']].to_csv('ft_train.txt', \n",
    "                                                  index = False, \n",
    "                                                  sep = ' ',\n",
    "                                                  header = None, \n",
    "                                                  quoting = csv.QUOTE_NONE, \n",
    "                                                  quotechar = \"\", \n",
    "                                                  escapechar = \" \")\n",
    "\n",
    "test[['target_ufc_bool', 'review_text']].to_csv('ft_test.txt', \n",
    "                                                 index = False, \n",
    "                                                 sep = ' ',\n",
    "                                                 header = None, \n",
    "                                                 quoting = csv.QUOTE_NONE, \n",
    "                                                 quotechar = \"\", \n",
    "                                                 escapechar = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-quebec",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.train_supervised(input='ft_train.txt', loss='hs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-digit",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "requested-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 0.621, 0.621)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.test('ft_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-transportation",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "relative-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] = train['review_text'].apply(ft_model.predict)\n",
    "test['predictions'] = test['review_text'].apply(ft_model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "separated-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality_prob(x):\n",
    "    if x[0][0] == '__label__True':\n",
    "        return round(x[1][0], 5)\n",
    "    elif x[0][0] == '__label__False':\n",
    "        return round(1 - x[1][0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "drawn-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ft_quality_prob'] = train['predictions'].apply(get_quality_prob)\n",
    "test['ft_quality_prob'] = test['predictions'].apply(get_quality_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['review_text', 'target_ufc_bool', 'predictions'])\n",
    "test = test.drop(columns=['review_text', 'target_ufc_bool', 'predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compound-raising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>ft_quality_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YTdE2qBNQGDCtiKih4ptQg</td>\n",
       "      <td>0.59451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YTo9yHDAxHZ3nTq4EPoDPg</td>\n",
       "      <td>0.54603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YTslRdJDQcMXM79scBk3fg</td>\n",
       "      <td>0.50559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YTv3rLJ7C8imbWNbRtngEQ</td>\n",
       "      <td>0.59314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YURMiu3t35P7vXx7bwnd7A</td>\n",
       "      <td>0.61289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  ft_quality_prob\n",
       "0  YTdE2qBNQGDCtiKih4ptQg          0.59451\n",
       "1  YTo9yHDAxHZ3nTq4EPoDPg          0.54603\n",
       "2  YTslRdJDQcMXM79scBk3fg          0.50559\n",
       "3  YTv3rLJ7C8imbWNbRtngEQ          0.59314\n",
       "4  YURMiu3t35P7vXx7bwnd7A          0.61289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-military",
   "metadata": {},
   "source": [
    "### Save Fasttext Results and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "running-listening",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b9e9cb07efe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_fasttext_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_fasttext_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2788\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2789\u001b[0m         )\n\u001b[1;32m   2790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSQLAlchemyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0;31m# GH34431\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mexec_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     def _query_iterator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[1;32m    747\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_insert_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1009\u001b[0m             )\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         )\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1317\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m             )\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                 )\n\u001b[1;32m   1513\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                     self.dialect.do_executemany(\n\u001b[0;32m-> 1257\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m                     )\n\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_executemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mEXECUTEMANY_DEFAULT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.to_sql('text_fasttext_train', con=engine, index=False, if_exists='replace')\n",
    "test.to_sql('text_fasttext_test', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save_model('fasttext_model_10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-memory",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-degree",
   "metadata": {},
   "source": [
    "https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-exclusive",
   "metadata": {},
   "source": [
    "!!! Model overloads memory !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "british-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = train.copy()\n",
    "bert_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "south-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "careful-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = bert_train['review_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=500)))\n",
    "tokenized_test = bert_test['review_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "patent-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized_train.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded_train = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train.values])\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recorded-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_train = np.where(padded_train != 0, 1, 0)\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = torch.tensor(padded_train)  \n",
    "attention_mask_train = torch.tensor(attention_mask_train)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_train = model(input_ids_train, attention_mask=attention_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor(padded_test)  \n",
    "attention_mask_test = torch.tensor(attention_mask_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_test = model(input_ids_test, attention_mask=attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_features = last_hidden_states_train[0][:,0,:].numpy()\n",
    "bert_test_features = last_hidden_states_test[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-waste",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data\n",
    "bert_forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "bert_forest = bert_forest.fit(bert_train_features, train['target_ufc_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-bottle",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results = bert_forest.predict(bert_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-retro",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['target_ufc_bool'], bert_cls_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
