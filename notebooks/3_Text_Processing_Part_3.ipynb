{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welcome-accused",
   "metadata": {},
   "source": [
    "# Text Processing - Yelp 2021 - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-matthew",
   "metadata": {},
   "source": [
    "This notebook covers:\n",
    "* Word Embedding Models\n",
    "* Word2Vec\n",
    "* Doc2Vec\n",
    "* Bert\n",
    "* Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-flower",
   "metadata": {},
   "source": [
    "## Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reverse-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeff/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Common Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Main NLP libraries\n",
    "import nltk\n",
    "import gensim\n",
    "# Word2Vec\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# Fasttext\n",
    "import csv\n",
    "import fasttext\n",
    "from gensim.utils import simple_preprocess\n",
    "# Bert - DistilBert\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-cursor",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "billion-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/full_data/analytics_ready/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"text_data_train.json\"\n",
    "filename_test = \"text_data_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stylish-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5523992 training records available\n",
    "# 1382379 testing records available\n",
    "num_records_to_load = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(file_location + filename_train, nrows=num_records_to_load, orient=\"records\", lines=True)\n",
    "test = pd.read_json(file_location + filename_test, nrows=num_records_to_load, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-teaching",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "responsible-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_text</th>\n",
       "      <th>target_ufc_bool</th>\n",
       "      <th>target_ufc_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---zlFD4Kgfatr0SbDh_zg</td>\n",
       "      <td>4</td>\n",
       "      <td>Been looking for a halfway decent Chinese/Amer...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--BcxYRlOpG0v7nVQWseYA</td>\n",
       "      <td>4</td>\n",
       "      <td>I visited Kyma last week for the first time an...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--KO46TSxWzv32x00s5w9Q</td>\n",
       "      <td>5</td>\n",
       "      <td>It might be the most expensive gelato I've eve...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--XNrIWxRUafMsGqzB5o0g</td>\n",
       "      <td>5</td>\n",
       "      <td>Love this place!  They have great antiques, be...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--aGgQu9HVva6F9fB2-0ew</td>\n",
       "      <td>4</td>\n",
       "      <td>Great salad and cold sandwich.. The soup is am...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  review_stars  \\\n",
       "0  ---zlFD4Kgfatr0SbDh_zg             4   \n",
       "1  --BcxYRlOpG0v7nVQWseYA             4   \n",
       "2  --KO46TSxWzv32x00s5w9Q             5   \n",
       "3  --XNrIWxRUafMsGqzB5o0g             5   \n",
       "4  --aGgQu9HVva6F9fB2-0ew             4   \n",
       "\n",
       "                                         review_text target_ufc_bool  \\\n",
       "0  Been looking for a halfway decent Chinese/Amer...           False   \n",
       "1  I visited Kyma last week for the first time an...           False   \n",
       "2  It might be the most expensive gelato I've eve...           False   \n",
       "3  Love this place!  They have great antiques, be...            True   \n",
       "4  Great salad and cold sandwich.. The soup is am...           False   \n",
       "\n",
       "   target_ufc_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "systematic-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   review_id         1000 non-null   object\n",
      " 1   review_stars      1000 non-null   int64 \n",
      " 2   review_text       1000 non-null   object\n",
      " 3   target_ufc_bool   1000 non-null   object\n",
      " 4   target_ufc_count  1000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ambient-fortune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     522\n",
       "False    478\n",
       "Name: target_ufc_bool, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Counts')\n",
    "train.target_ufc_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complex-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     528\n",
       "False    472\n",
       "Name: target_ufc_bool, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Counts')\n",
    "test.target_ufc_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sufficient-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Percent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    0.52200\n",
       "False   0.47800\n",
       "Name: target_ufc_bool, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Percent')\n",
    "train.target_ufc_bool.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finite-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Percent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    0.52800\n",
       "False   0.47200\n",
       "Name: target_ufc_bool, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Percent')\n",
    "test.target_ufc_bool.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-texas",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-sleeve",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/jungealexander/word2vec-and-random-forest-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-exhaust",
   "metadata": {},
   "source": [
    "### Preprocessing for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "genuine-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer used for splitting reviews into sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elegant-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Convert a review to a list of words. Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indonesian-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Split review into list of sentences where each sentence is a list of words.\n",
    "    Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "    # each sentence is furthermore split into words\n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "framed-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = []\n",
    "for review in train['review_text']:\n",
    "    training_text += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "passing-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'visited',\n",
       " 'kyma',\n",
       " 'last',\n",
       " 'week',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'and',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'it']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-charger",
   "metadata": {},
   "source": [
    "### Training Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chicken-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various word2vec parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 1    # Minimum word count                        \n",
    "num_workers = 3       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "\n",
    "w2v_model = Word2Vec(sentences=training_text,\n",
    "                     workers=num_workers, vector_size=num_features,\n",
    "                     min_count=min_word_count, window=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-experience",
   "metadata": {},
   "source": [
    "### Pre-Trained Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sitting-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goog_w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-laundry",
   "metadata": {},
   "source": [
    "### Preprocessing for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spatial-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features, local_trained_model):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0\n",
    "    if local_trained_model:\n",
    "        index2word_set = set(model.wv.index_to_key)  # words known to the model\n",
    "        for word in words:\n",
    "            if word in index2word_set: \n",
    "                nwords += 1\n",
    "                feature_vec = np.add(feature_vec,model.wv.get_vector(word))\n",
    "    else:\n",
    "        index2word_set = set(model.index_to_key)\n",
    "        for word in words:\n",
    "            if word in index2word_set: \n",
    "                nwords += 1\n",
    "                feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "great-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_feature_vecs(reviews, model, num_features, local_trained_model):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for all reviews\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for review in reviews:\n",
    "        review_feature_vecs[counter] = make_feature_vec(review, model, num_features, local_trained_model)\n",
    "        counter += 1\n",
    "    return review_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "portuguese-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average feature vectors for training and test sets\n",
    "clean_train_reviews = []\n",
    "for review in train['review_text']:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = get_avg_feature_vecs(clean_train_reviews, w2v_model, num_features, True)\n",
    "\n",
    "clean_test_reviews = []\n",
    "for review in test['review_text']:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "testDataVecs = get_avg_feature_vecs(clean_test_reviews, w2v_model, num_features, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-boundary",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wooden-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "forest = forest.fit(trainDataVecs, train['target_ufc_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-independence",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "numeric-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cls_results = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-filing",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "welcome-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.54      0.54       472\n",
      "        True       0.59      0.58      0.58       528\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.56      0.56      0.56      1000\n",
      "weighted avg       0.56      0.56      0.56      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['target_ufc_bool'], w2v_cls_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-shannon",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-minister",
   "metadata": {},
   "source": [
    "https://fasttext.cc/docs/en/supervised-tutorial.html  \n",
    "https://towardsdatascience.com/fasttext-for-text-classification-a4b38cbff27c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-creator",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "disciplinary-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train = train.copy()\n",
    "ft_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "jewish-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train['review_text'] = ft_train['review_text'].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "ft_train['target_ufc_bool'] = ft_train['target_ufc_bool'].apply(lambda x: '__label__' + x)\n",
    "\n",
    "ft_test['review_text'] = ft_test['review_text'].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "ft_test['target_ufc_bool'] = ft_test['target_ufc_bool'].apply(lambda x: '__label__' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "verbal-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train[['target_ufc_bool', 'review_text']].to_csv('ft_train.txt', \n",
    "                                                  index = False, \n",
    "                                                  sep = ' ',\n",
    "                                                  header = None, \n",
    "                                                  quoting = csv.QUOTE_NONE, \n",
    "                                                  quotechar = \"\", \n",
    "                                                  escapechar = \" \")\n",
    "\n",
    "ft_test[['target_ufc_bool', 'review_text']].to_csv('ft_test.txt', \n",
    "                                                 index = False, \n",
    "                                                 sep = ' ',\n",
    "                                                 header = None, \n",
    "                                                 quoting = csv.QUOTE_NONE, \n",
    "                                                 quotechar = \"\", \n",
    "                                                 escapechar = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-quebec",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "banner-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.train_supervised(input='ft_train.txt', wordNgrams = 2, epoch=25, lr=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-digit",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "requested-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 0.585, 0.585)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.test('ft_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-transportation",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "relative-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_test['predictions'] = ft_test['review_text'].apply(ft_model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "separated-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality_prob(x):\n",
    "    if x[0][0] == '__label__True':\n",
    "        return round(x[1][0], 5)\n",
    "    elif x[0][0] == '__label__False':\n",
    "        return round(1 - x[1][0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "drawn-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_test['ft_quality_prob'] = ft_test['predictions'].apply(get_quality_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "compound-raising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_text</th>\n",
       "      <th>target_ufc_bool</th>\n",
       "      <th>target_ufc_count</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ft_quality_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--p3d1axlnA7ka_p6hO-QQ</td>\n",
       "      <td>5</td>\n",
       "      <td>oh we love this place discovered it years ago ...</td>\n",
       "      <td>__label__False</td>\n",
       "      <td>0</td>\n",
       "      <td>((__label__True,), [0.9469317197799683])</td>\n",
       "      <td>0.94693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1v3W4XqQcIe44_I1lZYyA</td>\n",
       "      <td>5</td>\n",
       "      <td>didn smell anything bad like the other reviewe...</td>\n",
       "      <td>__label__True</td>\n",
       "      <td>5</td>\n",
       "      <td>((__label__True,), [0.9846104979515076])</td>\n",
       "      <td>0.98461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21y2QEKfhjxh2algH_0nQ</td>\n",
       "      <td>5</td>\n",
       "      <td>wow this place is good am so glad that work in...</td>\n",
       "      <td>__label__True</td>\n",
       "      <td>1</td>\n",
       "      <td>((__label__True,), [0.999253511428833])</td>\n",
       "      <td>0.99925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-358vecdAUh6ECkNfawvHw</td>\n",
       "      <td>5</td>\n",
       "      <td>for crepe you can choose up to flavors the men...</td>\n",
       "      <td>__label__False</td>\n",
       "      <td>0</td>\n",
       "      <td>((__label__True,), [0.6119228601455688])</td>\n",
       "      <td>0.61192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3_NmlYMibrapNEnS_gfcg</td>\n",
       "      <td>5</td>\n",
       "      <td>ve visited kyma twice now with approximately o...</td>\n",
       "      <td>__label__True</td>\n",
       "      <td>1</td>\n",
       "      <td>((__label__True,), [0.5569931864738464])</td>\n",
       "      <td>0.55699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  review_stars  \\\n",
       "0  --p3d1axlnA7ka_p6hO-QQ             5   \n",
       "1  -1v3W4XqQcIe44_I1lZYyA             5   \n",
       "2  -21y2QEKfhjxh2algH_0nQ             5   \n",
       "3  -358vecdAUh6ECkNfawvHw             5   \n",
       "4  -3_NmlYMibrapNEnS_gfcg             5   \n",
       "\n",
       "                                         review_text target_ufc_bool  \\\n",
       "0  oh we love this place discovered it years ago ...  __label__False   \n",
       "1  didn smell anything bad like the other reviewe...   __label__True   \n",
       "2  wow this place is good am so glad that work in...   __label__True   \n",
       "3  for crepe you can choose up to flavors the men...  __label__False   \n",
       "4  ve visited kyma twice now with approximately o...   __label__True   \n",
       "\n",
       "   target_ufc_count                               predictions  ft_quality_prob  \n",
       "0                 0  ((__label__True,), [0.9469317197799683])          0.94693  \n",
       "1                 5  ((__label__True,), [0.9846104979515076])          0.98461  \n",
       "2                 1   ((__label__True,), [0.999253511428833])          0.99925  \n",
       "3                 0  ((__label__True,), [0.6119228601455688])          0.61192  \n",
       "4                 1  ((__label__True,), [0.5569931864738464])          0.55699  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-memory",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-degree",
   "metadata": {},
   "source": [
    "https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-exclusive",
   "metadata": {},
   "source": [
    "!!! Model overloads memory !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "british-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = train.copy()\n",
    "bert_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "south-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "careful-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = bert_train['review_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=500)))\n",
    "tokenized_test = bert_test['review_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "patent-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized_train.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded_train = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train.values])\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recorded-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_train = np.where(padded_train != 0, 1, 0)\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = torch.tensor(padded_train)  \n",
    "attention_mask_train = torch.tensor(attention_mask_train)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_train = model(input_ids_train, attention_mask=attention_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor(padded_test)  \n",
    "attention_mask_test = torch.tensor(attention_mask_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states_test = model(input_ids_test, attention_mask=attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train_features = last_hidden_states_train[0][:,0,:].numpy()\n",
    "bert_test_features = last_hidden_states_test[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-waste",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data\n",
    "bert_forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "bert_forest = bert_forest.fit(bert_train_features, train['target_ufc_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-bottle",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_results = bert_forest.predict(bert_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-retro",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['target_ufc_bool'], bert_cls_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
