from sklearn.preprocessing import StandardScaler, PowerTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import (
    ElasticNet,
    LogisticRegression,
    SGDClassifier,
    SGDRegressor,
)
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import (
    RandomForestClassifier,
    RandomForestRegressor,
    HistGradientBoostingClassifier,
    HistGradientBoostingRegressor,
)
from xgboost.sklearn import XGBRegressor, XGBClassifier


class ModelSetupInfo:
    """
    Storage class for model hyperparameters and
    other setup info.
    For param dicts: All values must be lists for CV.
    Will work fine with a list with a single value.
    """

    def __init__(self):

        # PREPROCESSING
        self.scalars = {"Standard": StandardScaler, "Power": PowerTransformer}

        # REGRESSION
        self.reg_models = {
            "Elastic Net": ElasticNet,
            "Forest Reg": RandomForestRegressor,
            "HGB Reg": HistGradientBoostingRegressor,
            "XGB Reg": XGBRegressor,
        }
        self.reg_params_cv = {
            "Elastic Net": {
                "alpha": [0.5, 1, 1.5, 3],
                "l1_ratio": [0, 0.25, 0.5, 0.75, 1],
                "tol": [0.0001],
                "max_iter": [100, 1000, 10000],
                "random_state": [7],
            },
            "Forest Reg": {
                "n_estimators": [10, 50, 100, 200],
                "criterion": ["mse", "mae"],
                "max_depth": [None, 10, 100],
                "min_samples_split": [2, 10],
                "min_samples_leaf": [1, 5],
                "max_features": ["sqrt", 20],
                "max_leaf_nodes": [None, 100],
                "random_state": [7],
                "max_samples": [None],
            },
            "HGB Reg": {
                "loss": [
                    "least_squares",
                    "least_absolute_deviation",
                    "poisson",
                ],
                "learning_rate": [0.1, 0.4, 0.7],
                "max_iter": [10, 100, 1000],
                "l2_regularization": [0, 0.25, 0.5, 0.75],
                "max_depth": [10, 50, 100],
                "max_leaf_nodes": [31],
                "min_samples_leaf": [20],
            },
            "XGB Reg": {
                "learning_rate": [0.05, 0.1, 0.25],
                "n_estimators": [10, 100, 1000, 10000],
                "max_depth": [3, 5, 8, 10],
                "min_child_weight": [1, 3, 5],
                "gamma": [0, 0.2, 0.5],
                "subsample": [0.5, 0.8],
                "colsample_bytree": [0.5, 0.8],
                "reg_lambda": [0, 0.25, 0.5, 0.75],
                "random_state": [7],
            },
        }
        self.reg_params = {
            "Elastic Net": {
                "alpha": 1,
                "l1_ratio": 0.5,
                "tol": 0.0001,
                "max_iter": 1000,
                "random_state": 7,
            },
            "Forest Reg": {
                "n_estimators": 10,
                "criterion": "mse",
                "max_depth": 100,
                "min_samples_split": 2,
                "min_samples_leaf": 1,
                "max_features": "sqrt",
                "max_leaf_nodes": 100,
                "random_state": 7,
                "max_samples": 0.5,
            },
            "HGB Reg": {
                "loss": "least_squares",
                "learning_rate": 0.4,
                "max_iter": 100,
                "l2_regularization": 0.25,
                "max_depth": 50,
                "max_leaf_nodes": 31,
                "min_samples_leaf": 20,
            },
            "XGB Reg": {
                "learning_rate": 0.1,
                "n_estimators": 1000,
                "max_depth": 10,
                "min_child_weight": 3,
                "gamma": 0.2,
                "subsample": 0.8,
                "colsample_bytree": 0.8,
                "reg_lambda": 0.5,
                "random_state": 7,
            },
        }
        self.reg_scoring = {
            "R2 Score": "r2",
            "MSE": "neg_mean_squared_error",
            "RMSE": "neg_root_mean_squared_error",
            "MAE": "neg_mean_absolute_error",
        }

        # CLASSIFICATION
        self.cls_models = {
            "Log Reg": LogisticRegression,
            "Forest Cls": RandomForestClassifier,
            "HGB Cls": HistGradientBoostingClassifier,
            "XGB Cls": XGBClassifier,
        }
        self.cls_params_cv = {
            "Log Reg": {
                "penalty": ["l2"],
                "tol": [0.0001],
                "C": [0.1, 0.5, 1.0, 2],
                "class_weight": ["balanced"],
                "random_state": [7],
                "solver": ["saga", "lbfgs"],
                "max_iter": [50, 100, 1000, 5000],
            },
            "Forest Cls": {
                "n_estimators": [10, 50, 100, 200],
                "criterion": ["gini"],
                "max_depth": [None, 100],
                "min_samples_split": [2, 10],
                "min_samples_leaf": [1, 5],
                "max_features": ["sqrt", 20],
                "max_leaf_nodes": [None, 100],
                "class_weight": [None, "balanced"],
                "max_samples": [None],
                "random_state": [7],
                "n_jobs": [-1],
            },
            "HGB Cls": {
                "loss": ["auto"],
                "learning_rate": [0.01, 0.1, 0.4],
                "max_iter": [50, 100, 1000],
                "max_depth": [None, 5, 10],
                "max_leaf_nodes": [31],
                "min_samples_leaf": [20],
                "l2_regularization": [0, 0.25, 0.5, 0.75],
                "random_state": [7],
            },
            "XGB Cls": {
                "learning_rate": [0.01, 0.1, 0.4],
                "n_estimators": [50, 100, 1000, 2000],
                "max_depth": [None, 5, 10],
                "min_child_weight": [1, 3, 5],
                "gamma": [0, 0.2, 0.5],
                "subsample": [0.5, 0.8],
                "colsample_bytree": [0.5, 0.8],
                "reg_lambda": [0, 0.25, 0.5, 0.75],
                "random_state": [7],
            },
        }
        self.cls_params = {
            "Log Reg": {
                "penalty": "elasticnet",
                "tol": 0.0001,
                "C": 1.0,
                "class_weight": "balanced",
                "l1_ratio": 0.25,
                "random_state": 7,
                "solver": "saga",
                "max_iter": 1000,
            },
            "Forest Cls": {
                "n_estimators": 100,
                "criterion": "gini",
                "max_depth": None,
                "min_samples_split": 2,
                "min_samples_leaf": 1,
                "max_features": "sqrt",
                "max_leaf_nodes": None,
                "class_weight": None,
                "max_samples": None,
                "random_state": 7,
            },
            "HGB Cls": {
                "loss": "auto",
                "learning_rate": 0.4,
                "max_iter": 100,
                "max_leaf_nodes": 31,
                "min_samples_leaf": 20,
                "l2_regularization": 0.25,
                "random_state": 7,
            },
            "XGB Cls": {
                "learning_rate": 0.1,
                "n_estimators": 100,
                "max_depth": 10,
                "min_child_weight": 3,
                "gamma": 0.2,
                "subsample": 0.8,
                "colsample_bytree": 0.8,
                "reg_lambda": 0.5,
                "random_state": 7,
            },
        }
        self.cls_scoring = {
            "Accuracy": "accuracy",
            "Balanced Accuracy": "balanced_accuracy",
            "Precision": "precision_weighted",
            "Recall": "recall_weighted",
            "F1_Score": "f1_weighted",
            "ROC_AUC": "roc_auc_ovr_weighted",
        }

        # NLP
        # Naive Bayes and Support Vector Machines are common in NLP.
        # Can also use forests, boosting, and neural nets.

        self.pos_list = [
            "ADJ",
            "ADP",
            "ADV",
            "AUX",
            "CONJ",
            "DET",
            "INTJ",
            "NOUN",
            "NUM",
            "PART",
            "PRON",
            "PROPN",
            "PUNCT",
            "SCONJ",
            "SYM",
            "VERB",
            "X",
        ]
        self.dep_list = [
            "ROOT",
            "acl",
            "acomp",
            "advcl",
            "advmod",
            "agent",
            "amod",
            "appos",
            "attr",
            "aux",
            "auxpass",
            "case",
            "cc",
            "ccomp",
            "compound",
            "conj",
            "csubj",
            "csubjpass",
            "dative",
            "dep",
            "det",
            "dobj",
            "expl",
            "intj",
            "mark",
            "meta",
            "neg",
            "nmod",
            "npadvmod",
            "nsubj",
            "nsubjpass",
            "nummod",
            "oprd",
            "parataxis",
            "pcomp",
            "pobj",
            "poss",
            "preconj",
            "predet",
            "prep",
            "prt",
            "punct",
            "quantmod",
            "relcl",
            "xcomp",
        ]
        self.ent_list = [
            "CARDINAL",
            "DATE",
            "EVENT",
            "FAC",
            "GPE",
            "LANGUAGE",
            "LAW",
            "LOC",
            "MONEY",
            "NORP",
            "ORDINAL",
            "ORG",
            "PERCENT",
            "PERSON",
            "PRODUCT",
            "QUANTITY",
            "TIME",
            "WORK_OF_ART",
        ]
        self.nlp_models = {
            "sgd_cls": SGDClassifier,
            "sgd_reg": SGDRegressor,
            "naive_bayes": MultinomialNB,
        }
        self.nlp_params_cv = {
            "sgd_cls": {
                "loss": ["hinge"],
                "penalty": ["l2"],
                "alpha": [0.001],
                "random_state": [7],
                "max_iter": [100],
                "class_weight": ["balanced"],
            },
            "sgd_reg": {
                "loss": [
                    "squared_loss",
                    "huber",
                    "epsilon_insensitive",
                    "squared_epsilon_insensitive",
                ],
                "penalty": ["elasticnet"],
                "l1_ratio": [0, 0.15, 0.35, 0.5, 0.75],
                "alpha": [0.0001, 0.001, 0.1],
                "random_state": [7],
                "max_iter": [50, 100, 1000],
            },
            "naive_bayes": {"alpha": [0.5]},
        }
        self.nlp_params = {
            "sgd_cls": {
                "loss": ["hinge"],
                "penalty": ["l2"],
                "alpha": [0.001],
                "random_state": [7],
                "max_iter": [100],
                "class_weight": ["balanced"],
            },
            "sgd_reg": {
                "loss": ["squared_loss"],
                "penalty": ["elasticnet"],
                "l1_ratio": [0.15],
                "alpha": [0.0001],
                "random_state": [7],
                "max_iter": [100],
            },
            "naive_bayes": {"alpha": [0.5]},
        }
        self.feature_names = {
            "review_stars": "review_stars",
            "review_stars_minus_user_avg": "review_stars_minus_user_avg",
            "review_stars_minus_business_avg": "review_stars_minus_business_avg",
            "review_stars_v_user_avg_sqr_diff": "review_stars_v_user_avg_sqr_diff",
            "review_stars_v_business_avg_sqr_diff": "review_stars_v_business_avg_sqr_diff",
            "business_avg_stars": "business_avg_stars",
            "business_review_count_TD": "business_review_count_TD",
            "business_checkin_count_TD": "business_checkin_count_TD",
            "business_checkins_per_review_TD": "business_checkins_per_review_TD",
            "user_avg_stars": "user_avg_stars",
            "user_days_active_at_review_time": "user_days_active_at_review_time",
            "user_total_ufc_TD": "User Total Votes",
            "user_review_count_TD": "user_review_count_TD",
            "user_friend_count_TD": "user_friend_count_TD",
            "user_fans_TD": "user_fans_TD",
            "user_compliments_TD": "user_compliments_TD",
            "user_elite_count_TD": "user_elite_count_TD",
            "user_years_since_most_recent_elite_TD": "user_years_since_most_recent_elite_TD",
            "user_ufc_per_review_TD": "User Votes Per Review",
            "user_fans_per_review_TD": "user_fans_per_review_TD",
            "user_ufc_per_years_yelping_TD": "User Votes Per Year",
            "user_fans_per_years_yelping_TD": "user_fans_per_years_yelping_TD",
            "user_fan_per_rev_x_ufc_per_rev_TD": "user_fan_per_rev_x_ufc_per_rev_TD",
            "review_text_char_count": "review_text_char_count",
            "review_text_word_count": "review_text_word_count",
            "review_text_char_per_word": "review_text_char_per_word",
            "review_text_sgd_cls_pred": "SVM Model Predictions",
            "review_text_naive_bayes_pred": "Naive Bayes Model Predictions",
            "review_text_token_count": "review_text_token_count",
            "review_text_perc_stop_words": "review_text_perc_stop_words",
            "review_text_perc_ent": "review_text_perc_ent",
            "review_text_perc_part": "review_text_perc_part",
            "review_text_perc_adp": "review_text_perc_adp",
            "review_text_perc_intj": "review_text_perc_intj",
            "review_text_perc_conj": "review_text_perc_conj",
            "review_text_perc_pron": "review_text_perc_pron",
            "review_text_perc_det": "review_text_perc_det",
            "review_text_perc_num": "review_text_perc_num",
            "review_text_perc_punct": "review_text_perc_punct",
            "review_text_perc_verb": "review_text_perc_verb",
            "review_text_perc_x": "review_text_perc_x",
            "review_text_perc_adv": "review_text_perc_adv",
            "review_text_perc_sconj": "review_text_perc_sconj",
            "review_text_perc_noun": "review_text_perc_noun",
            "review_text_perc_adj": "review_text_perc_adj",
            "review_text_perc_aux": "review_text_perc_aux",
            "review_text_perc_sym": "review_text_perc_sym",
            "review_text_perc_propn": "review_text_perc_propn",
            "review_text_perc_root": "review_text_perc_root",
            "review_text_perc_acl": "review_text_perc_acl",
            "review_text_perc_acomp": "review_text_perc_acomp",
            "review_text_perc_advcl": "review_text_perc_advcl",
            "review_text_perc_advmod": "review_text_perc_advmod",
            "review_text_perc_agent": "review_text_perc_agent",
            "review_text_perc_amod": "review_text_perc_amod",
            "review_text_perc_appos": "review_text_perc_appos",
            "review_text_perc_attr": "review_text_perc_attr",
            "review_text_perc_auxpass": "review_text_perc_auxpass",
            "review_text_perc_case": "review_text_perc_case",
            "review_text_perc_cc": "review_text_perc_cc",
            "review_text_perc_ccomp": "review_text_perc_ccomp",
            "review_text_perc_compound": "review_text_perc_compound",
            "review_text_perc_csubj": "review_text_perc_csubj",
            "review_text_perc_csubjpass": "review_text_perc_csubjpass",
            "review_text_perc_dative": "review_text_perc_dative",
            "review_text_perc_dep": "review_text_perc_dep",
            "review_text_perc_dobj": "review_text_perc_dobj",
            "review_text_perc_expl": "review_text_perc_expl",
            "review_text_perc_mark": "review_text_perc_mark",
            "review_text_perc_meta": "review_text_perc_meta",
            "review_text_perc_neg": "review_text_perc_neg",
            "review_text_perc_nmod": "review_text_perc_nmod",
            "review_text_perc_npadvmod": "review_text_perc_npadvmod",
            "review_text_perc_nsubj": "review_text_perc_nsubj",
            "review_text_perc_nsubjpass": "review_text_perc_nsubjpass",
            "review_text_perc_nummod": "review_text_perc_nummod",
            "review_text_perc_oprd": "review_text_perc_oprd",
            "review_text_perc_parataxis": "review_text_perc_parataxis",
            "review_text_perc_pcomp": "review_text_perc_pcomp",
            "review_text_perc_pobj": "review_text_perc_pobj",
            "review_text_perc_poss": "review_text_perc_poss",
            "review_text_perc_preconj": "review_text_perc_preconj",
            "review_text_perc_predet": "review_text_perc_predet",
            "review_text_perc_prep": "review_text_perc_prep",
            "review_text_perc_prt": "review_text_perc_prt",
            "review_text_perc_quantmod": "review_text_perc_quantmod",
            "review_text_perc_relcl": "review_text_perc_relcl",
            "review_text_perc_xcomp": "review_text_perc_xcomp",
            "review_text_perc_cardinal": "review_text_perc_cardinal",
            "review_text_perc_date": "review_text_perc_date",
            "review_text_perc_event": "review_text_perc_event",
            "review_text_perc_fac": "review_text_perc_fac",
            "review_text_perc_gpe": "review_text_perc_gpe",
            "review_text_perc_language": "review_text_perc_language",
            "review_text_perc_law": "review_text_perc_law",
            "review_text_perc_loc": "review_text_perc_loc",
            "review_text_perc_money": "review_text_perc_money",
            "review_text_perc_norp": "review_text_perc_norp",
            "review_text_perc_ordinal": "review_text_perc_ordinal",
            "review_text_perc_org": "review_text_perc_org",
            "review_text_perc_percent": "review_text_perc_percent",
            "review_text_perc_person": "review_text_perc_person",
            "review_text_perc_product": "review_text_perc_product",
            "review_text_perc_quantity": "review_text_perc_quantity",
            "review_text_perc_time": "review_text_perc_time",
            "review_text_perc_work_of_art": "review_text_perc_work_of_art",
        }


if __name__ == "__main__":
    pass
